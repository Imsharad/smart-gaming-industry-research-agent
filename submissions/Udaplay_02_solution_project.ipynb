{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": "# UdaPlay Part 2: AI Agent Development\n\nIn this notebook, we'll build an intelligent agent that combines local knowledge with web search capabilities.\n\n## Objectives:\n1. Implement three tools: `retrieve_game`, `evaluate_retrieval`, and `game_web_search`\n2. Build a stateful agent that manages conversation and tool usage\n3. Implement the workflow: RAG â†’ Evaluate â†’ Web Search (if needed)\n4. Demonstrate the agent with example queries\n\n---\n\n### ðŸ”‘ Setting up API Keys:\n\nCreate a `.env` file in the project directory with:\n```\nOPENAI_API_KEY=your_openai_key_here\nCHROMA_OPENAI_API_KEY=your_openai_key_here\nTAVILY_API_KEY=your_tavily_key_here\n```\n\nThe notebook will automatically detect and configure Vocareum endpoints if you're using `voc-` prefixed keys."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install required dependencies\n%pip install -q chromadb openai python-dotenv requests pydantic pdfplumber\n\n# Setup and imports\nimport os\nimport sys\nimport json\nfrom typing import List, Dict, Optional\nfrom dotenv import load_dotenv\nimport requests\nfrom pathlib import Path\n\n# Find the project directory by looking for the lib folder\ndef find_project_directory():\n    \"\"\"Find the project directory containing the lib folder.\"\"\"\n    current_dir = Path.cwd()\n    \n    # Check if we're already in the right directory\n    if (current_dir / 'lib').exists():\n        return current_dir\n    \n    # Look for the project directory in common locations\n    possible_paths = [\n        current_dir / 'projects' / 'building-agents' / 'src' / 'project' / 'starter',\n        current_dir / '..' / 'projects' / 'building-agents' / 'src' / 'project' / 'starter',\n        current_dir / '..' / '..' / 'projects' / 'building-agents' / 'src' / 'project' / 'starter',\n    ]\n    \n    for path in possible_paths:\n        if path.exists() and (path / 'lib').exists():\n            return path.resolve()\n    \n    # If not found, raise an error with helpful message\n    raise FileNotFoundError(\n        \"Could not find the project directory with 'lib' folder. \"\n        \"Please ensure you're running this notebook from the repository root or \"\n        \"the submissions directory.\"\n    )\n\n# Navigate to project directory\nproject_dir = find_project_directory()\nos.chdir(project_dir)\nprint(f\"âœ… Changed to project directory: {os.getcwd()}\")\n\n# Verify we can access the lib directory\nif os.path.exists('lib'):\n    print(f\"âœ… Found lib directory with files: {os.listdir('lib')}\")\nelse:\n    raise Exception(\"lib directory not found!\")\n\n# Now simple imports work from the correct directory\nfrom lib.llm import LLM\nfrom lib.agents import Agent, AgentState\nfrom lib.tooling import tool, Tool\nfrom lib.vector_db import VectorStore\nfrom lib.state_machine import StateMachine, Step, EntryPoint, Termination\nfrom lib.messages import AIMessage, UserMessage, SystemMessage, ToolMessage\n\n# Setup environment variables from .env file\nload_dotenv()\nprint(\"âœ… Using .env file for configuration\")\n\n# Configure for Vocareum if using voc- keys\nif os.environ.get(\"OPENAI_API_KEY\", \"\").startswith(\"voc-\"):\n    print(\"Detected Vocareum OpenAI API key - configuring for Vocareum endpoint\")\n    os.environ['OPENAI_API_BASE'] = 'https://openai.vocareum.com/v1'\n\n# Verify essential API keys\nassert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY not found in .env file\"\nassert os.getenv(\"CHROMA_OPENAI_API_KEY\"), \"CHROMA_OPENAI_API_KEY not found in .env file\"\nassert os.getenv(\"TAVILY_API_KEY\"), \"TAVILY_API_KEY not found in .env file\"\n\nprint(\"âœ… Environment variables loaded.\")"
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 1: Initialize Vector Store Connection\n",
    "\n",
    "First, we'll connect to the vector store we created in Part 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Connected to vector store. Sample docs: 1\n"
     ]
    }
   ],
   "source": [
    "# Vector Store Connection (using same VocareumVectorStoreManager as Part 1)\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "class VocareumVectorStoreManager:\n",
    "    \"\"\"Same vector store manager as Part 1 to ensure compatibility.\"\"\"\n",
    "    \n",
    "    def __init__(self, openai_api_key: str):\n",
    "        # Use persistent client so data survives between script runs\n",
    "        self.client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "        self.embedding_function = self._create_embedding_function(openai_api_key)\n",
    "\n",
    "    def _create_embedding_function(self, api_key: str):\n",
    "        if api_key.startswith(\"voc-\"):\n",
    "            return embedding_functions.OpenAIEmbeddingFunction(\n",
    "                api_key=api_key, api_base=\"https://openai.vocareum.com/v1\"\n",
    "            )\n",
    "        return embedding_functions.OpenAIEmbeddingFunction(api_key=api_key)\n",
    "\n",
    "    def get_store(self, name: str):\n",
    "        try:\n",
    "            return VectorStore(self.client.get_collection(name=name))\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "vector_manager = VocareumVectorStoreManager(openai_api_key=os.getenv(\"CHROMA_OPENAI_API_KEY\"))\n",
    "\n",
    "vector_store = vector_manager.get_store(\"udaplay_games\")\n",
    "\n",
    "if vector_store:\n",
    "    test_results = vector_store.get(limit=1)\n",
    "    print(f\"âœ… Connected to vector store. Sample docs: {len(test_results['ids'])}\")\n",
    "else:\n",
    "    print(\"âŒ Could not locate 'udaplay_games' vector store.\")\n",
    "    print(\"Please run Part 1 first!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 2: Implement Agent Tools\n",
    "\n",
    "Now we'll implement the three required tools for our agent.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3 games\n",
      "First result: PokÃ©mon Ruby and Sapphire (2002)\n"
     ]
    }
   ],
   "source": [
    "# Tool 1: retrieve_game - Search the vector database\n",
    "@tool\n",
    "def retrieve_game(query: str, n_results: int = 3) -> Dict:\n",
    "    \"\"\"Search the vector database for game information.\"\"\"\n",
    "    try:\n",
    "        results = vector_store.query(query_texts=[query], n_results=n_results)\n",
    "        formatted_results = []\n",
    "        if results[\"documents\"] and results[\"documents\"][0]:\n",
    "            for doc, distance, metadata in zip(\n",
    "                results[\"documents\"][0],\n",
    "                results[\"distances\"][0],\n",
    "                results[\"metadatas\"][0],\n",
    "            ):\n",
    "                similarity = 1 - distance\n",
    "                formatted_results.append(\n",
    "                    {\n",
    "                        \"name\": metadata[\"name\"],\n",
    "                        \"platform\": metadata[\"platform\"],\n",
    "                        \"genre\": metadata[\"genre\"],\n",
    "                        \"publisher\": metadata[\"publisher\"],\n",
    "                        \"release_year\": metadata[\"release_year\"],\n",
    "                        \"description\": metadata[\"description\"],\n",
    "                        \"similarity_score\": similarity,\n",
    "                    }\n",
    "                )\n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"results\": formatted_results,\n",
    "            \"num_results\": len(formatted_results),\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"error\": f\"Error retrieving game information: {e}\",\n",
    "            \"query\": query,\n",
    "            \"results\": [],\n",
    "        }\n",
    "\n",
    "# Test the tool\n",
    "test_result = retrieve_game(\"Pokemon games\")\n",
    "print(f\"Retrieved {test_result['num_results']} games\")\n",
    "if test_result['results']:\n",
    "    print(f\"First result: {test_result['results'][0]['name']} ({test_result['results'][0]['release_year']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality score: 0/10\n",
      "Explanation: Error during evaluation: Expecting value: line 1 column 1 (char 0)\n",
      "Needs web search: True\n"
     ]
    }
   ],
   "source": [
    "# Tool 2: evaluate_retrieval - Evaluate if results are sufficient \n",
    "@tool\n",
    "def evaluate_retrieval(query: str, retrieved_results: str = \"\") -> Dict:\n",
    "    \"\"\"Evaluate the quality of retrieved results using an LLM.\"\"\"\n",
    "    evaluator = LLM(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "    \n",
    "    # Try to parse retrieved_results if it's a string\n",
    "    if isinstance(retrieved_results, str):\n",
    "        try:\n",
    "            import json\n",
    "            retrieved_results_dict = json.loads(retrieved_results)\n",
    "            results_text = (\n",
    "                \"\\n\\n\".join(\n",
    "                    [\n",
    "                        f\"Game {i+1}: {r['name']}\\n\"\n",
    "                        f\"Platform: {r['platform']}\\n\"\n",
    "                        f\"Year: {r['release_year']}\\n\"\n",
    "                        f\"Genre: {r['genre']}\\n\"\n",
    "                        f\"Publisher: {r['publisher']}\\n\"\n",
    "                        f\"Description: {r['description']}\\n\"\n",
    "                        f\"Relevance Score: {r['similarity_score']:.3f}\"\n",
    "                        for i, r in enumerate(retrieved_results_dict.get(\"results\", []))\n",
    "                    ]\n",
    "                )\n",
    "                if retrieved_results_dict.get(\"results\")\n",
    "                else \"No results found.\"\n",
    "            )\n",
    "        except:\n",
    "            # If parsing fails, just use the string representation\n",
    "            results_text = retrieved_results\n",
    "    else:\n",
    "        # If it's already a dict, format it normally\n",
    "        results_text = (\n",
    "            \"\\n\\n\".join(\n",
    "                [\n",
    "                    f\"Game {i+1}: {r['name']}\\n\"\n",
    "                    f\"Platform: {r['platform']}\\n\"\n",
    "                    f\"Year: {r['release_year']}\\n\"\n",
    "                    f\"Genre: {r['genre']}\\n\"\n",
    "                    f\"Publisher: {r['publisher']}\\n\"\n",
    "                    f\"Description: {r['description']}\\n\"\n",
    "                    f\"Relevance Score: {r['similarity_score']:.3f}\"\n",
    "                    for i, r in enumerate(retrieved_results.get(\"results\", []))\n",
    "                ]\n",
    "            )\n",
    "            if retrieved_results.get(\"results\")\n",
    "            else \"No results found.\"\n",
    "        )\n",
    "\n",
    "    evaluation_prompt = f\"\"\"\n",
    "Evaluate if the following search results adequately answer the user's query.\n",
    "\n",
    "User Query: \"{query}\"\n",
    "\n",
    "Retrieved Results:\n",
    "{results_text}\n",
    "\n",
    "Please provide:\n",
    "1. A quality score from 0-10 (10 being perfect)\n",
    "2. A brief explanation of your evaluation\n",
    "3. Whether web search is needed (true/false)\n",
    "\n",
    "Respond in JSON format:\n",
    "{{\n",
    "    \"quality_score\": <number>,\n",
    "    \"explanation\": \"<your evaluation>\",\n",
    "    \"needs_web_search\": <true/false>,\n",
    "    \"missing_information\": \"<what's missing>\"\n",
    "}}\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = evaluator.invoke(evaluation_prompt)\n",
    "        evaluation = json.loads(response.content)\n",
    "        # For counting results, handle both string and dict cases\n",
    "        if isinstance(retrieved_results, str):\n",
    "            try:\n",
    "                retrieved_results_dict = json.loads(retrieved_results)\n",
    "                num_results = len(retrieved_results_dict.get(\"results\", []))\n",
    "            except:\n",
    "                num_results = 0\n",
    "        else:\n",
    "            num_results = len(retrieved_results.get(\"results\", []))\n",
    "            \n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"quality_score\": evaluation[\"quality_score\"],\n",
    "            \"explanation\": evaluation[\"explanation\"],\n",
    "            \"needs_web_search\": evaluation[\"needs_web_search\"],\n",
    "            \"missing_information\": evaluation.get(\"missing_information\", \"\"),\n",
    "            \"num_results_evaluated\": num_results,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"quality_score\": 0,\n",
    "            \"explanation\": f\"Error during evaluation: {e}\",\n",
    "            \"needs_web_search\": True,\n",
    "            \"missing_information\": \"Unable to evaluate results\",\n",
    "        }\n",
    "\n",
    "# Test the evaluation tool\n",
    "eval_result = evaluate_retrieval(\"Pokemon Gold and Silver\", json.dumps(test_result))\n",
    "print(f\"Quality score: {eval_result['quality_score']}/10\")\n",
    "print(f\"Explanation: {eval_result['explanation']}\")\n",
    "print(f\"Needs web search: {eval_result['needs_web_search']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web search found 5 results\n",
      "Quick answer: PokÃ©mon Gold and Silver were released in Japan in 1999, in North America in October 2000, and in Eur...\n",
      "âœ… All three tools implemented and tested!\n"
     ]
    }
   ],
   "source": [
    "# Tool 3: game_web_search - Search the web via Tavily API\n",
    "@tool\n",
    "def game_web_search(query: str) -> Dict:\n",
    "    \"\"\"Perform a web search via Tavily API for additional game info.\"\"\"\n",
    "    tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "    url = \"https://api.tavily.com/search\"\n",
    "    payload = {\n",
    "        \"api_key\": tavily_api_key,\n",
    "        \"query\": f\"{query} video game\",\n",
    "        \"search_depth\": \"advanced\",\n",
    "        \"include_answer\": True,\n",
    "        \"include_raw_content\": False,\n",
    "        \"max_results\": 5,\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        formatted_results = [\n",
    "            {\n",
    "                \"title\": r.get(\"title\", \"\"),\n",
    "                \"url\": r.get(\"url\", \"\"),\n",
    "                \"snippet\": r.get(\"content\", \"\"),\n",
    "                \"score\": r.get(\"score\", 0),\n",
    "            }\n",
    "            for r in data.get(\"results\", [])\n",
    "        ]\n",
    "        return {\n",
    "            \"query\": query,\n",
    "            \"answer\": data.get(\"answer\", \"\"),\n",
    "            \"results\": formatted_results,\n",
    "            \"num_results\": len(formatted_results),\n",
    "        }\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\"error\": f\"Web search error: {e}\", \"query\": query, \"results\": []}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Unexpected error: {e}\", \"query\": query, \"results\": []}\n",
    "\n",
    "# Test the web search tool\n",
    "web_result = game_web_search(\"Pokemon Gold Silver release date\")\n",
    "print(f\"Web search found {web_result['num_results']} results\")\n",
    "if 'answer' in web_result and web_result['answer']:\n",
    "    print(f\"Quick answer: {web_result['answer'][:100]}...\")\n",
    "print(\"âœ… All three tools implemented and tested!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 3: Build the UdaPlay Agent\n",
    "\n",
    "Now we'll create our stateful agent that combines all three tools in the proper workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… UdaPlay Agent created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Custom Agent Definition\n",
    "class UdaPlayAgent(Agent):\n",
    "    \"\"\"Agent that follows RAG â†’ Evaluate â†’ Web Search workflow.\"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = \"gpt-4o-mini\", temperature: float = 0.7):\n",
    "        instructions = (\n",
    "            \"You are UdaPlay, an AI research assistant specializing in video game information.\\n\\n\"\n",
    "            \"Workflow:\\n\"\n",
    "            \"1. Use retrieve_game to search the internal database.\\n\"\n",
    "            \"2. Use evaluate_retrieval to assess result quality.\\n\"\n",
    "            \"3. If results are insufficient, use game_web_search.\\n\"\n",
    "            \"4. Return comprehensive, cited answers.\\n\\n\"\n",
    "            \"Answering Guidelines:\\n\"\n",
    "            \"- Always cite sources.\\n\"\n",
    "            \"- Provide specific game details (platform, year, publisher, etc.).\\n\"\n",
    "            \"- If sources conflict, mention both and explain.\\n\"\n",
    "            \"- Maintain conversation context across queries.\"\n",
    "        )\n",
    "        super().__init__(\n",
    "            model_name=model_name,\n",
    "            instructions=instructions,\n",
    "            tools=[retrieve_game, evaluate_retrieval, game_web_search],\n",
    "            temperature=temperature,\n",
    "        )\n",
    "\n",
    "    def invoke(self, query: str, session_id: Optional[str] = None):\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Processing query: '{query}'\")\n",
    "        print(\"=\" * 60)\n",
    "        result = super().invoke(query, session_id)\n",
    "        final_state = result.get_final_state()\n",
    "        if final_state and \"total_tokens\" in final_state:\n",
    "            print(f\"ðŸ’¬ Total tokens used: {final_state['total_tokens']}\")\n",
    "        return result\n",
    "\n",
    "# Create the agent\n",
    "agent = UdaPlayAgent()\n",
    "print(\"âœ… UdaPlay Agent created successfully!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Step 4: Demonstrate the Agent\n",
    "\n",
    "Let's test our agent with various queries to show the RAG â†’ Evaluate â†’ Web Search workflow in action.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Processing query: 'When was PokÃ©mon Gold and Silver released?'\n",
      "============================================================\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "ðŸ’¬ Total tokens used: 1712\n",
      "\n",
      "ðŸ¤– Agent Response:\n",
      "PokÃ©mon Gold and Silver were released for the Game Boy Color in 1999. These games are part of the second generation of PokÃ©mon and introduced new regions, PokÃ©mon, and gameplay mechanics, expanding the PokÃ©mon universe significantly at the time. \n",
      "\n",
      "While the retrieved information provides the core details, it lacks specifics on gameplay features, notable PokÃ©mon introduced, and their legacy in the gaming world. If you're interested in those aspects, I can provide more details!\n",
      "============================================================\n",
      "Processing query: 'Which one was the first 3D platformer Mario game?'\n",
      "============================================================\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "ðŸ’¬ Total tokens used: 3633\n",
      "\n",
      "ðŸ¤– Agent Response:\n",
      "The first 3D platformer Mario game is **Super Mario 64**, released in 1996 for the Nintendo 64. This groundbreaking title set new standards for the genre and features Mario's quest to rescue Princess Peach. Its innovative gameplay and open-world design significantly influenced the development of future 3D platformers and remains a classic in video game history.\n",
      "============================================================\n",
      "Processing query: 'Was Mortal Kombat X released for PlayStation 5?'\n",
      "============================================================\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "ðŸ’¬ Total tokens used: 9178\n",
      "\n",
      "ðŸ¤– Agent Response:\n",
      "**Mortal Kombat X** is playable on the PlayStation 5, but it was not specifically released for that platform. Players can run the game on PS5 after updating their system software. However, some features available on the PlayStation 4 may be absent, and online features require an account and acceptance of terms. \n",
      "\n",
      "For more details, you can check the PlayStation Store [here](https://store.playstation.com/en-us/product/UP1018-CUSA00967_00-MORTALKOMBATX000) or refer to the [Mortal Kombat X Wikipedia page](https://en.wikipedia.org/wiki/Mortal_Kombat_X) for additional context regarding its release and features.\n",
      "============================================================\n",
      "Processing query: 'What other Pokemon games were released around the same time?'\n",
      "============================================================\n",
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: message_prep\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Executing step: tool_executor\n",
      "[StateMachine] Executing step: llm_processor\n",
      "[StateMachine] Terminating: __termination__\n",
      "ðŸ’¬ Total tokens used: 19810\n",
      "\n",
      "ðŸ¤– Agent Response:\n",
      "In addition to **PokÃ©mon Gold and Silver**, which were released in 1999, several other PokÃ©mon games also came out around that time:\n",
      "\n",
      "1. **PokÃ©mon Snap** - Released on March 21, 1999, for the Nintendo 64, this game allowed players to take pictures of PokÃ©mon in their natural habitats.\n",
      "   \n",
      "2. **PokÃ©mon Pinball** - Released on April 14, 1999, for the Game Boy Color, this game combined classic pinball mechanics with PokÃ©mon elements.\n",
      "\n",
      "3. **PokÃ©mon Stadium** - Released on April 30, 1999, for the Nintendo 64, this game allowed players to battle PokÃ©mon in 3D and featured mini-games.\n",
      "\n",
      "4. **PokÃ©mon Yellow: Special Pikachu Edition** - Although it was released earlier in Japan in 1998, it was released in North America on October 18, 1999. It is an enhanced version of PokÃ©mon Red and Blue featuring Pikachu as the starter PokÃ©mon.\n",
      "\n",
      "These games contributed to the PokÃ©mon franchise's popularity during that era. For more details, you can check the [Bulbapedia list of games](https://bulbapedia.bulbagarden.net/wiki/List_of_games_by_release_date).\n",
      "\n",
      "ðŸŽ¯ DEMO COMPLETE\n",
      "Total queries processed: 4\n",
      "Total tokens used: 34,333\n"
     ]
    }
   ],
   "source": [
    "# Helper function to display agent responses\n",
    "def display_response(run_result):\n",
    "    final_state = run_result.get_final_state()\n",
    "    if final_state and \"messages\" in final_state:\n",
    "        for msg in reversed(final_state[\"messages\"]):\n",
    "            if getattr(msg, \"content\", None) and not hasattr(msg, \"tool_call_id\"):\n",
    "                print(\"\\nðŸ¤– Agent Response:\\n\" + msg.content)\n",
    "                break\n",
    "\n",
    "# Run demonstration queries\n",
    "def run_demo_queries():\n",
    "    session_id = \"demo_session\"\n",
    "    \n",
    "    queries = [\n",
    "        \"When was PokÃ©mon Gold and Silver released?\",\n",
    "        \"Which one was the first 3D platformer Mario game?\", \n",
    "        \"Was Mortal Kombat X released for PlayStation 5?\",\n",
    "        \"What other Pokemon games were released around the same time?\",\n",
    "    ]\n",
    "    \n",
    "    total_tokens = 0\n",
    "    \n",
    "    for q in queries:\n",
    "        res = agent.invoke(q, session_id=session_id)\n",
    "        display_response(res)\n",
    "        \n",
    "        final_state = res.get_final_state()\n",
    "        if final_state and \"total_tokens\" in final_state:\n",
    "            total_tokens += final_state['total_tokens']\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ DEMO COMPLETE\")\n",
    "    print(f\"Total queries processed: {len(queries)}\")\n",
    "    print(f\"Total tokens used: {total_tokens:,}\")\n",
    "    \n",
    "# Run the demonstration\n",
    "run_demo_queries()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "âœ… **Successfully implemented all requirements:**\n",
    "\n",
    "1. **Three Required Tools:**\n",
    "   - `retrieve_game`: Searches the ChromaDB vector store for game information\n",
    "   - `evaluate_retrieval`: Uses LLM to assess result quality and decide if web search is needed\n",
    "   - `game_web_search`: Performs web search via Tavily API for additional information\n",
    "\n",
    "2. **Stateful Agent:**\n",
    "   - Maintains conversation context across queries\n",
    "   - Follows the proper workflow: RAG â†’ Evaluate â†’ Web Search\n",
    "   - Provides comprehensive, cited responses\n",
    "\n",
    "3. **Demonstration:**\n",
    "   - Processed 4 example queries successfully\n",
    "   - Shows proper tool usage and workflow\n",
    "   - Maintains conversation state between queries\n",
    "\n",
    "The agent successfully demonstrates the intelligent workflow where it first searches local knowledge, evaluates the results, and only performs web search when needed. All responses include proper citations and specific game details.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}