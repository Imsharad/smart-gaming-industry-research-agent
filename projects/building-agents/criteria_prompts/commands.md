# MASTER TASK LIST FOR UDAPLAY PROJECT EVALUATION
# Tailored for the AgentsVille Trip Planner / Udaplay Game Information Agent Project

## üìã PHASE 1: INITIAL SETUP & CONTEXT GATHERING
‚òê Set student directory variable: `STUDENT_DIR="stu_X"`
‚òê Read and understand evaluation context files
  ‚òê Read prompt.md for Udaplay project overview
  ‚òê Read reviewer_tip.md for grading guidelines
  ‚òê Verify student has both required notebooks:
    - `Udaplay_01_*project.ipynb` (RAG implementation)
    - `Udaplay_02_*project.ipynb` (Agent implementation)
  ‚òê Check for supporting directories:
    - games/ (should contain 15 JSON files)
    - lib/ (optional, may contain helper modules)
    - newchromadb/ or chroma_db/ (vector database storage)
  ‚òê Create feedback directory: `mkdir -p ${STUDENT_DIR}/feedback`

## üîç PHASE 2: SYSTEMATIC CRITERION EVALUATION

### ‚úÖ Criterion 1: RAG - Prepare and process video game dataset for vector database
‚òê Read criteria1.md file completely
‚òê **Subcriteria 1.1: Data Loading & Processing**
  ‚òê Check notebook exists: `ls -la ${STUDENT_DIR}/Udaplay_01_*project.ipynb`
  ‚òê Verify JSON loading: `grep -n "json.load\|pd.read_json\|json.loads" ${STUDENT_DIR}/Udaplay_01_*project.ipynb`
  ‚òê Check game directory refs: `grep -n "games\|data_dir\|game.*json" ${STUDENT_DIR}/Udaplay_01_*project.ipynb`
  ‚òê Verify game files exist: `ls -la ${STUDENT_DIR}/games/*.json 2>/dev/null`
  ‚òê Count game files (should be 15): `find ${STUDENT_DIR} -name "*.json" -path "*/games/*" | wc -l`
  ‚òê Check data formatting: `grep -n "DataFrame\|dict\|format\|process" ${STUDENT_DIR}/Udaplay_01_*project.ipynb`
  ‚òê Verify document structure: `grep -n "metadata\|document\|content\|embedding" ${STUDENT_DIR}/Udaplay_01_*project.ipynb`

‚òê **Subcriteria 1.2: Vector Database Setup**
  ‚òê Check for ChromaDB imports: `grep -n "chromadb\|ChromaDB\|PersistentClient" ${STUDENT_DIR}/Udaplay_01_*project.ipynb`
  ‚òê Verify persistence: `grep -n "persist_directory\|storage\|persistent\|PersistentClient" ${STUDENT_DIR}/Udaplay_01_*project.ipynb`
  ‚òê Check DB files exist: `find ${STUDENT_DIR} -name "*.sqlite3" -o -name "chroma.sqlite3" 2>/dev/null`
  ‚òê Verify collection creation: `grep -n "create_collection\|get_or_create_collection" ${STUDENT_DIR}/Udaplay_01_*project.ipynb`
  ‚òê Check embedding config: `grep -n "embedding\|embed\|OpenAIEmbeddings" ${STUDENT_DIR}/Udaplay_01_*project.ipynb`
  ‚òê Verify data insertion: `grep -n "add\|insert\|upsert\|add_documents" ${STUDENT_DIR}/Udaplay_01_*project.ipynb`
  ‚òê Check document count: `grep -n "count\|len\|collection.count" ${STUDENT_DIR}/Udaplay_01_*project.ipynb`

‚òê **Subcriteria 1.3: Semantic Search Demonstration**
  ‚òê Check query implementation: `grep -n "query\|search\|retrieve\|similarity" ${STUDENT_DIR}/Udaplay_01_*project.ipynb`
  ‚òê Verify query methods: `grep -n "collection.query\|similarity_search" ${STUDENT_DIR}/Udaplay_01_*project.ipynb`
  ‚òê Check results handling: `grep -n "results\|distances\|documents\|metadatas" ${STUDENT_DIR}/Udaplay_01_*project.ipynb`
  ‚òê Look for game queries: `grep -i "racing\|rpg\|playstation\|nintendo\|genre" ${STUDENT_DIR}/Udaplay_01_*project.ipynb`
  ‚òê Verify outputs exist: `grep -A5 "output_type": ${STUDENT_DIR}/Udaplay_01_*project.ipynb | grep -v "outputs.*[]"`
  ‚òê Check result display: `grep -n "print.*result\|display\|pprint" ${STUDENT_DIR}/Udaplay_01_*project.ipynb`
  
‚òê **Quick Pipeline Check:**
  ```bash
  echo "=== Checking ${STUDENT_DIR} ===" && \
  echo "Notebook exists: $(ls ${STUDENT_DIR}/Udaplay_01_*project.ipynb 2>/dev/null | wc -l)" && \
  echo "Game files: $(find ${STUDENT_DIR} -name "*.json" -path "*/games/*" 2>/dev/null | wc -l)" && \
  echo "ChromaDB refs: $(grep -c "chromadb\|ChromaDB" ${STUDENT_DIR}/Udaplay_01_*project.ipynb 2>/dev/null)" && \
  echo "Query calls: $(grep -c "query\|search" ${STUDENT_DIR}/Udaplay_01_*project.ipynb 2>/dev/null)"
  ```
‚òê Document findings and generate feedback/1.md with PASS/FAIL status

### ‚öôÔ∏è Criterion 2: Agent Development - Three tools (retrieval, evaluation, web search)
‚òê Read criteria2.md file completely
‚òê **Subcriteria 2.1: Tool Implementation**
  ‚òê Check tool definitions: `grep -n "@tool\|def.*tool\|class.*Tool" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Check lib modules: `grep -n "@tool\|def.*tool" ${STUDENT_DIR}/lib/*.py 2>/dev/null`
  ‚òê **Retrieval Tool:**
    - Verify implementation: `grep -n "retrieve\|retrieval\|get_game\|search_game" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
    - Check vector search: `grep -n "collection.query\|similarity_search" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê **Evaluation Tool:**
    - Check implementation: `grep -n "evaluate\|eval\|quality\|relevance\|assess" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
    - Verify function: `grep -n "def evaluate\|class.*Evaluat" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê **Web Search Tool:**
    - Check API integration: `grep -n "tavily\|serper\|google\|bing\|web.*search" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
    - Verify API key: `grep -n "TavilyClient\|api_key\|API_KEY" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`

‚òê **Subcriteria 2.2: Tool Integration**
  ‚òê Check agent integration: `grep -n "tools=\[\|tool_list\|available_tools" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Verify tool binding: `grep -n "bind_tools\|tool_executor\|execute_tool" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Check workflow: `grep -n "workflow\|StateGraph\|Graph\|pipeline" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Verify tool execution: `grep -n "tool_calls\|function_call\|invoke.*tool" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Check return formats: `grep -n "return.*{.*\|return.*dict\|return.*json" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`

‚òê **Subcriteria 2.3: Workflow Order (Internal ‚Üí Evaluate ‚Üí Web)**
  ‚òê Check workflow sequence: `grep -n -A10 "internal.*first\|try.*internal" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Verify evaluation step: `grep -n -A10 "evaluate.*result\|check.*quality" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Check web fallback: `grep -n -A10 "fallback\|web.*search.*if" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Verify conditional logic: `grep -n "if.*retriev\|if.*evaluat\|if.*quality" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Check state transitions: `grep -n "next.*state\|transition\|should_.*" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  
‚òê **Quick Tool Check:**
  ```bash
  echo "=== Checking Tools in ${STUDENT_DIR} ===" && \
  echo "Retrieval tool refs: $(grep -c "retrieve\|retrieval" ${STUDENT_DIR}/Udaplay_02_*project.ipynb 2>/dev/null)" && \
  echo "Evaluation tool refs: $(grep -c "evaluate\|assess\|quality" ${STUDENT_DIR}/Udaplay_02_*project.ipynb 2>/dev/null)" && \
  echo "Web search tool refs: $(grep -c "tavily\|web.*search" ${STUDENT_DIR}/Udaplay_02_*project.ipynb 2>/dev/null)" && \
  echo "Tool decorators: $(grep -c "@tool" ${STUDENT_DIR}/Udaplay_02_*project.ipynb 2>/dev/null)"
  ```
‚òê Document findings and generate feedback/2.md with PASS/FAIL status

### ü§ñ Criterion 3: Stateful Agent - Conversation management & workflow
‚òê Read criteria3.md file completely
‚òê **Subcriteria 3.1: Agent Class/Function with State**
  ‚òê Check agent class: `grep -n "class.*Agent\|class.*Assistant" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Verify initialization: `grep -n "__init__.*self\|def.*create_agent" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Check state variables: `grep -n "self.state\|self.memory\|self.history" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Verify conversation history: `grep -n "conversation.*history\|message.*history" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Check memory implementation: `grep -n "memory\|Memory\|ConversationBuffer" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Verify session handling: `grep -n "session\|Session\|conversation_id" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`

‚òê **Subcriteria 3.2: Multi-Query Session Support**
  ‚òê Check multiple queries: `grep -n "while\|for.*query\|multiple.*queries" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Verify context preservation: `grep -n "append.*history\|add.*message\|update.*context" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Check conversation continuity: `grep -n "follow.*up\|previous.*answer\|earlier" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Verify state updates: `grep -n "state\[.*\]_=\|update.*state" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Look for query examples: `grep -B2 -A5 "query.*1\|Query.*:" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Check context references: `grep -n "as.*mentioned\|previously\|earlier" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`

‚òê **Subcriteria 3.3: State Machine/Workflow Implementation**
  ‚òê Check state machine: `grep -n "StateGraph\|state.*machine\|StateMachine" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Verify workflow structure: `grep -n "LangGraph\|workflow\|WorkflowGraph" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Check nodes/edges: `grep -n "add_node\|add_edge\|add_conditional" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Verify transitions: `grep -n "transition\|next_state\|should_.*" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Check compilation: `grep -n "compile\|build.*graph\|create.*workflow" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Look for modular steps: `grep -n "def.*node\|def.*step\|def.*stage" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`

‚òê **Subcriteria 3.4: Clear & Cited Answers**
  ‚òê Check citations: `grep -n "source\|citation\|cite\|reference" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Verify formatting: `grep -n "format.*response\|structure.*answer" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Check synthesis: `grep -n "combine\|merge\|synthesize" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Verify web citations: `grep -B5 -A5 "Information is from.*http" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê **CRITICAL**: Manually verify cited URLs match actual search results (not hallucinated)
  
‚òê **Quick State Check:**
  ```bash
  echo "=== Checking State Management in ${STUDENT_DIR} ===" && \
  echo "Agent class defs: $(grep -c "class.*Agent" ${STUDENT_DIR}/Udaplay_02_*project.ipynb 2>/dev/null)" && \
  echo "State variables: $(grep -c "self.state\|self.memory" ${STUDENT_DIR}/Udaplay_02_*project.ipynb 2>/dev/null)" && \
  echo "Workflow refs: $(grep -c "StateGraph\|workflow" ${STUDENT_DIR}/Udaplay_02_*project.ipynb 2>/dev/null)" && \
  echo "Multiple queries: $(grep -c "query.*\[0-9\]" ${STUDENT_DIR}/Udaplay_02_*project.ipynb 2>/dev/null)"
  ```
‚òê Document findings and generate feedback/3.md with PASS/FAIL status

### üìä Criterion 4: Agent Demonstration - At least 3 example queries
‚òê Read criteria4.md file completely
‚òê **Subcriteria 4.1: Three Example Queries**
  ‚òê Check notebook exists: `ls -la ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Count test queries: `grep -c "query.*=\|question.*=\|test.*query" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Find Query 1: `grep -n "query.*1\|Query.*1\|Example.*1" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Find Query 2: `grep -n "query.*2\|Query.*2\|Example.*2" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Find Query 3: `grep -n "query.*3\|Query.*3\|Example.*3" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Verify diverse query types:
    - Release dates: `grep -i "release.*date\|when.*released" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
    - Platforms: `grep -i "platform\|playstation\|xbox\|nintendo" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
    - Publishers: `grep -i "publisher\|developer\|company" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
    - Genres: `grep -i "genre\|type.*game\|rpg\|racing" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Verify executions: `grep -n "agent.invoke\|agent.run\|agent.query" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`

‚òê **Subcriteria 4.2: Visible Reasoning & Tool Usage**
  ‚òê Check reasoning visibility: `grep -n "reasoning\|thinking\|thought\|Step.*:" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Verify tool usage logs: `grep -n "Using.*tool\|Calling.*tool\|Executing.*tool" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Check retrieval attempts: `grep -n "Retrieved.*:\|Found.*:\|Results.*:" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Verify evaluation display: `grep -n "Evaluation.*:\|Quality.*:\|Relevance.*:" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Check final answers: `grep -n "Final.*answer\|Answer.*:\|Response.*:" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Verify verbose output: `grep -n "verbose.*True\|debug.*True" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`

‚òê **Subcriteria 4.3: Report with Citations**
  ‚òê Check citations present: `grep -n "Source.*:\|Citation.*:\|Reference.*:" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Verify web sources: `grep -n "http\|www\|URL.*:\|Link.*:" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Check internal sources: `grep -n "database\|collection\|internal.*source" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Look for report sections: `grep -n "report\|summary\|Report\|Summary" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  ‚òê Verify metadata: `grep -n "metadata\|confidence\|source.*type" ${STUDENT_DIR}/Udaplay_02_*project.ipynb`
  
‚òê **Quick Demo Check:**
  ```bash
  echo "=== Checking Demonstrations in ${STUDENT_DIR} ===" && \
  echo "Test queries found: $(grep -c "query.*=\|question.*=" ${STUDENT_DIR}/Udaplay_02_*project.ipynb 2>/dev/null)" && \
  echo "Agent executions: $(grep -c "agent.invoke\|agent.run" ${STUDENT_DIR}/Udaplay_02_*project.ipynb 2>/dev/null)" && \
  echo "Tool usage logs: $(grep -c "tool.*called\|Using.*tool" ${STUDENT_DIR}/Udaplay_02_*project.ipynb 2>/dev/null)" && \
  echo "Citations: $(grep -c "Source.*:\|Citation.*:" ${STUDENT_DIR}/Udaplay_02_*project.ipynb 2>/dev/null)"
  ```
  
‚òê **Final Completeness Check:**
  ```bash
  echo "=== FINAL DEMONSTRATION COMPLETENESS ===" && \
  QUERIES=$(grep -c "query.*=\|question.*=" ${STUDENT_DIR}/Udaplay_02_*project.ipynb 2>/dev/null) && \
  [ $QUERIES -ge 3 ] && echo "PASS: $QUERIES queries (min: 3)" || echo "FAIL: Only $QUERIES queries (needs 3)"
  ```
‚òê Document findings and generate feedback/4.md with PASS/FAIL status

## üìä PHASE 3: FINAL ASSESSMENT & SUMMARY
‚òê Review all four criterion feedback files
‚òê Calculate overall PASS/FAIL status
  ‚òê All 4 criteria must PASS for overall PASS
  ‚òê Note any exceptional implementations
  ‚òê Identify areas for improvement
‚òê Create comprehensive summary.md with:
  ‚òê Overall result (PASS/FAIL)
  ‚òê Individual criterion results
    - Criterion 1: RAG - [PASS/FAIL]
    - Criterion 2: Agent Development - [PASS/FAIL]
    - Criterion 3: Stateful Agent - [PASS/FAIL]
    - Criterion 4: Performance Demo - [PASS/FAIL]
  ‚òê Key strengths (specific examples)
  ‚òê Areas for improvement (constructive feedback)
  ‚òê Next steps recommendations
‚òê Verify all files are created:
  - feedback/1.md
  - feedback/2.md
  - feedback/3.md
  - feedback/4.md
  - summary.md

## üìù FEEDBACK TEMPLATE FOR UDAPLAY PROJECT
Each feedback file should follow this format:
```markdown
# Criterion [N]: [NAME] - [PASS/FAIL] [‚úÖ/‚ùå]

[Opening statement about performance on this criterion]

‚Ä¢ **[Specific Requirement 1]**: [Evidence with file references/line numbers]
‚Ä¢ **[Specific Requirement 2]**: [Evidence with file references/line numbers]  
‚Ä¢ **[Specific Requirement 3]**: [Evidence with file references/line numbers]
‚Ä¢ **[Key Strength]**: [Highlight exceptional work if any]

[Detailed analysis paragraph with specific examples from their code]

**Status: [PASS/FAIL]**
```

## üéÆ PROJECT-SPECIFIC DETAILS TO VERIFY
‚òê **Data Requirements:**
  - Exactly 15 game JSON files in games/ directory
  - Each game has: Name, Platform, YearOfRelease, Genre, Publisher, Description
  - Games include titles like Gran Turismo, Mario Kart, Pok√©mon, etc.

‚òê **Technical Stack:**
  - ChromaDB for vector database (or alternative)
  - OpenAI embeddings (or alternative)
  - Tavily API for web search (or alternative)
  - LangChain/LangGraph or custom implementation

‚òê **Agent Workflow Must Follow:**
  1. Internal retrieval from vector DB first
  2. Evaluate quality of retrieved results
  3. Web search only if internal results insufficient

‚òê **Common Student Variations to Accept:**
  - Different vector DBs (Weaviate, Pinecone, Qdrant)
  - Different embedding models (HuggingFace, Cohere)
  - Different web search APIs (Serper, Google, Bing)
  - Custom implementations vs framework-based

## üö® CRITICAL EVALUATION POINTS
‚òê **DO NOT FAIL IF:**
  - Student uses different libraries/frameworks as long as requirements met
  - Simple state management as long as it works
  - Agent can't answer every query perfectly if process is demonstrated
  - Different file/folder structure as long as core files present

‚òê **MUST FAIL IF:**
  - Missing either required notebook
  - No vector database implementation
  - Missing any of the three required tools
  - No demonstration of at least 3 queries
  - No evidence of stateful conversation
  - Hallucinated web citations (URLs that don't match actual search results)

## üéØ QUALITY ASSURANCE CHECKLIST
‚òê All verification commands executed (no shortcuts taken)
‚òê Evidence-based evaluation with specific line numbers
‚òê Constructive feedback tone throughout
‚òê Clear PASS/FAIL for each criterion
‚òê Overall assessment aligns with criteria results
‚òê Actionable improvement suggestions provided
‚òê Student's unique approach acknowledged

--- 
*This evaluation template is specifically tailored for the Udaplay/AgentsVille Trip Planner Project focusing on video game information retrieval using RAG and agent-based systems.*
