Architecting an Autonomous Assignment Verification System with Claude Sub-agentsPart 1: The Claude Sub-agent Paradigm: From Monolithic Models to Collaborative SystemsThe evolution of large language models (LLMs) has entered a new phase, transitioning from singular, monolithic systems to sophisticated, collaborative multi-agent architectures. Anthropic's Claude sub-agents represent a significant milestone in this paradigm shift, enabling the development of complex, autonomous workflows that are modular, scalable, and cost-effective.1 Understanding this architecture is foundational to building the requested student assignment verification system, as its core principles directly address the workflow's most critical requirements.1.1 The Architectural Shift: Introducing the Orchestrator-Worker PatternThe Claude sub-agent architecture is built upon a classic and powerful computing model: the orchestrator-worker pattern.1 Instead of relying on a single, massive LLM to handle a complex sequence of tasks, this model employs a hierarchical division of labor.A lead agent, typically a powerful model like Claude Opus 4, acts as the orchestrator. Its primary role is not to execute every task but to analyze a high-level goal, decompose it into smaller, logical subtasks, and delegate these subtasks to a team of specialized worker agents.1 These worker agents are often more cost-efficient models, such as Claude Sonnet 4, each designed to perform a specific, narrowly-defined function with high proficiency.1This architectural choice mirrors the microservices design prevalent in modern software engineering. By breaking down a large problem into smaller, independent services (or agents), the system gains immense flexibility, resilience, and maintainability. For the assignment verification workflow, this means that instead of attempting to construct a single, brittle prompt that handles file operations, rubric parsing, and iterative analysis, the system can be composed of distinct, single-purpose agents. One agent can be an expert in file management, another in parsing text, and a third in code analysis. This modularity not only simplifies development but also makes the system easier to debug and upgrade. Furthermore, this tiered approach provides significant resource optimization. By using the more powerful and expensive Opus model for high-level reasoning and orchestration while leveraging the faster, cheaper Sonnet model for repetitive, focused tasks, organizations can reduce token-related costs by an estimated 40-60% compared to a monolithic Opus-only approach.11.2 Anatomy of a Sub-agent: The Building Blocks of AutonomyEach worker sub-agent is a self-contained unit of intelligence, defined by a specific set of characteristics that enable its specialized function and, critically, its operational independence.The Isolated Context Window: The most significant feature of a sub-agent is its independent context window, typically 200,000 tokens in size.1 This memory space is completely isolated from the orchestrator and all other sub-agents.1 When an orchestrator invokes a sub-agent, it passes only the necessary information for the specific task. The sub-agent performs its work within its private context and returns a structured result. This isolation is the mechanism that directly enables the "isolated environment" and "fresh slate" required for each criterion check in the assignment verification workflow. There is no risk of "context pollution," where information from a previous task bleeds into and corrupts a current one—a common failure mode in single-prompt systems.3 This architectural feature means the design challenge shifts from complex state management and memory clearing to the effective design of a stateless loop managed by the orchestrator.File-Based Definition: Sub-agents are not abstract entities; they are defined in simple, human-readable Markdown files with a YAML frontmatter section.3 This tangible, file-based nature is a cornerstone of their power. It allows agents to be version-controlled using systems like Git, peer-reviewed, and shared across teams or the open-source community.5 This transforms the practice of prompt engineering into a more rigorous discipline of AI systems design. The YAML frontmatter contains key metadata, including the agent's name, a description that governs its automatic invocation, and an optional list of tools it is permitted to use.3The System Prompt: The body of the Markdown file, following the YAML frontmatter, serves as the sub-agent's system prompt. This is its "constitution" or operational charter, defining its role, expertise, constraints, and desired output format.3 The precision and clarity of this prompt are directly proportional to the agent's performance and reliability. A well-crafted system prompt transforms a general-purpose model into a domain-specific expert.Granular Tool Permissions: The tools field within the YAML frontmatter provides a powerful security and control mechanism. It allows a developer to specify exactly which capabilities the agent can access, such as the ability to read files (read), write files (write), execute shell commands (bash), or search for text (grep).3 This enables the implementation of the principle of least privilege, a fundamental security best practice.10 For the assignment verification workflow, this means the agent responsible for analyzing student code can be denied permission to execute arbitrary shell commands, mitigating potential security risks associated with running untrusted code.1.3 Communication, Lifecycle, and OrchestrationThe interaction between the orchestrator and its workers is governed by a well-defined protocol and lifecycle, ensuring efficient and robust operation.Communication Protocol: The system relies on a structured message-passing protocol for inter-agent communication. The orchestrator dispatches a task specification to a worker, which typically includes a clear objective, relevant context, operational constraints, and the expected structure of the output.1 The worker agent processes this request and returns its results in a structured format. This formal data exchange is crucial for maintaining the integrity of the workflow and preventing the context pollution that plagues less structured systems.Agent Lifecycle: The lifecycle of a sub-agent is managed asynchronously, which is key to the system's efficiency.1 When the orchestrator needs a task performed, it "spawns" a new sub-agent instance. This process—including initialization and loading of the agent's context—occurs without blocking the orchestrator. The lead agent can continue its own processing or even spawn multiple agents to work in parallel.1 Once an agent completes its task, it returns its result and is terminated, ensuring its isolated context window is discarded.Result Aggregation: A primary responsibility of the orchestrator is to manage the aggregation of results from its various workers. As sub-agents complete their tasks and return their findings, the orchestrator collects this information. Anthropic describes this as a "result aggregation pipeline," which can involve validating data quality, resolving conflicts between different agent outputs, and synthesizing the individual pieces of information into a single, coherent final report.1 In the context of the assignment verification workflow, the orchestrator will be responsible for collecting each individual feedback-N.md file and compiling them into the final grading summary for the student.Part 2: Practical Implementation: A "Hello World" File Analysis LoopTo translate the architectural theory into practice, this section provides a hands-on tutorial for building a simple yet illustrative multi-agent system. This "Hello World" example will create a workflow that scans a directory for files containing a specific keyword, demonstrating the fundamental mechanics of sub-agent creation, configuration, and invocation.2.1 Setting Up Your Agentic EnvironmentThe foundation of any Claude sub-agent system is its file structure. Claude Code automatically recognizes and loads agents from specific directories, allowing for clear organization and scoping.The .claude/agents/ Directory: Sub-agents are stored in a hidden directory named .claude. They can be defined at two levels:Project-Scoped: Placing agent files in a .claude/agents/ directory at the root of a specific project makes them available only within that project. This is the recommended approach for specialized workflows like assignment verification, as it ensures the agents are version-controlled alongside the project's other assets and are highly portable.3User-Scoped: Placing agent files in ~/.claude/agents/ (the user's home directory) makes them globally available across all projects. This is useful for general-purpose utility agents.When both project and user-scoped agents with the same name exist, the project-level agent takes precedence, allowing for project-specific overrides of global agents.5The /agents Command: The primary interface for managing sub-agents within the Claude Code terminal is the /agents command.3 This command opens an interactive manager that simplifies the creation, editing, and listing of available agents. For new users, this is the most straightforward way to create the initial agent file, as it guides the user through defining the name, description, and other essential properties.62.2 Crafting a KeywordScanner Sub-agentFor this example, a sub-agent named keyword-scanner will be created. Its sole purpose is to find files containing a specific keyword.First, create the file .claude/agents/keyword-scanner.md. The contents of this file will be as follows:name: keyword-scanner
description: MUST BE USED to scan a directory for files containing a specific keyword. Takes a directory path and a keyword as input.
tools: [read, grep, glob]You are a specialized file analysis tool. Your sole function is to identify all files within a given directory that contain a specific keyword.You must return a structured, machine-readable list of the full file paths that contain the keyword. Do not summarize, interpret, or modify the files in any way. Your output should be a simple list, with one file path per line.YAML Frontmatter Analysis:name: keyword-scanner: This defines the agent's unique identifier, which will be used for explicit invocation.3description: MUST BE USED...: This is the critical field for automatic delegation. The phrasing is intentional and precise. When the orchestrator receives a natural language request like "scan these files for a keyword," this description allows it to intelligently match the task to this agent.7 The description effectively serves as the agent's API contract, signaling its function and required inputs to the orchestrator. Using strong, directive language like "MUST BE USED" is a documented best practice for improving the reliability of automatic invocation.9tools: [read, grep, glob]: This list strictly limits the agent's capabilities to what is necessary for its task, adhering to the principle of least privilege. It can list files (glob), search their contents (grep), and read them (read), but it cannot write, edit, or execute arbitrary commands.3System Prompt Analysis:The prompt is narrowly scoped and highly directive. It establishes a clear role ("specialized file analysis tool"), defines a single function ("identify all files..."), and specifies a precise output format ("a simple list, with one file path per line"). This level of specificity is crucial for creating reliable and predictable agents.52.3 The Orchestrator's Prompt: Executing the LoopWith the keyword-scanner sub-agent defined, the orchestrator (the main Claude Code agent) can now be instructed to use it. This is done via a prompt in the main terminal window.Example Orchestrator Prompt:My project files are located in the ./student-submission/ directory. Please use the keyword-scanner sub-agent to find all files within that directory that contain the keyword 'import pandas'. After the agent is finished, present the identified file paths in a markdown table with a single column titled "Files Containing Keyword".Analysis of the Prompt:This prompt demonstrates two key orchestration concepts. First, it uses explicit invocation by directly naming the agent to be used ("Use the keyword-scanner sub-agent"). While Claude Code supports automatic delegation based on the agent's description, explicit invocation provides a higher degree of control and predictability, which is often desirable for structured, mission-critical workflows.3Second, it showcases the orchestrator's role in post-processing. The sub-agent is designed to return a simple, machine-readable list. The orchestrator then takes this raw output and fulfills the user's final request to format it into a human-readable markdown table. This separation of concerns—the worker agent performs the core task, and the orchestrator handles the final presentation—is a hallmark of effective multi-agent system design.Part 3: Blueprint for the Student Assignment Verification WorkflowThis section provides a detailed architectural blueprint for the user's specific workflow. The system is decomposed into a team of specialized agents, each with a distinct role, orchestrated by a master prompt that manages the end-to-end process. This design directly leverages the principles of isolation, modularity, and structured communication discussed previously.3.1 High-Level System Decomposition and Agent RosterThe proposed architecture consists of three distinct sub-agents and a master orchestrator. This division of labor ensures that each component has a single, well-defined responsibility, which enhances reliability and simplifies maintenance. The agents are:WorkspaceManager: Handles the initial environment setup.RubricInterpreter: Parses the grading criteria into a structured plan.CriterionAnalyzer: Executes the core, iterative evaluation of each criterion.The following table provides a high-level overview of the system's architecture, outlining each agent's role, required permissions, interaction pattern, and expected output. This serves as a map for the entire system before delving into the specific implementation of each component.Table 1: Sub-agent Roster for the Assignment Verification WorkflowAgent NameCore ResponsibilityKey Tools RequiredInvocation PatternOutput ArtifactWorkspaceManagerHandles initial file setup: download, extract, and move submission files.bash (with scoped permissions for curl, unzip, mv, mkdir)Sequential (First step)Path to prepared workspaceRubricInterpreterParses rubric files and generates a structured, machine-readable list of criteria for analysis.read, globSequential (Second step)A JSON or structured text list of criteriaCriterionAnalyzerEvaluates a single criterion against the codebase and generates one feedback file.read, grep, find, writeIterative (Spawned in a loop, one instance per criterion)A single feedback/{n}.md fileThis design pattern is analogous to the well-established MapReduce paradigm in distributed computing. The RubricInterpreter acts as the initial "mapper," transforming the unstructured rubric into a structured list of tasks (the criteria). The orchestration loop then "maps" each of these tasks to an independent, stateless worker—the CriterionAnalyzer. This step is where the crucial isolation occurs. Finally, the orchestrator's final action serves as the "reducer," gathering the individual outputs (feedback/{n}.md) and consolidating them into a single, final report. Recognizing this pattern allows for the application of its principles, such as the potential for parallel execution of the CriterionAnalyzer agents to significantly accelerate the evaluation of assignments with numerous criteria.13.2 Agent Profile: WorkspaceManagerPurpose: This agent automates the initial, often tedious, setup phase of the workflow. Its sole responsibility is to take a URL pointing to a student's submission (as a zip file), download it, extract its contents, and place them in a standardized, clean workspace directory. This ensures that the rest of the workflow operates on a consistent and predictable file structure.File: .claude/agents/workspace-manager.mdname: workspace-manager
description: MUST BE USED to download, unzip, and prepare a student submission workspace from a URL.
tools: [bash]You are an automated file system utility. Your only task is to prepare a project workspace for analysis. You will be given a URL to a zip file.You must perform the following steps in order:Create a new, empty directory named submission_workspace. If it already exists, delete its contents first to ensure a clean slate.Download the zip file from the provided URL into the submission_workspace directory.Unzip the contents of the file within the directory.Delete the original zip file to clean up the workspace.Upon successful completion, return only the absolute path to the submission_workspace directory and nothing else.3.3 Agent Profile: RubricInterpreterPurpose: This agent acts as a pre-processor for the evaluation criteria. It decouples the core analysis logic from the specific format of the rubric or prompt files. It reads one or more text-based files, identifies the distinct evaluation criteria, and outputs them as a simple, structured, machine-readable list. This makes the main orchestration loop more robust, as it no longer needs to parse complex natural language instructions.File: .claude/agents/rubric-interpreter.mdname: rubric-interpreter
description: MUST BE USED to read rubric files and extract a numbered list of distinct evaluation criteria.
tools: [read, glob]You are a rubric analysis expert. You will be given a path to a directory containing rubric and prompt files (e.g., .md, .txt).Your task is to read all relevant files, identify the distinct, individual evaluation criteria, and output them as a simple, numbered list. Each line in your output must represent one and only one criterion to be evaluated. Your output will be used to drive an automated evaluation loop, so clarity and atomicity are paramount.Example Output:The student correctly implemented the calculate_mean function.The code is well-commented according to the project's style guide.The README.md file provides clear instructions for running the code.3.4 Agent Profile: CriterionAnalyzerPurpose: This is the core worker of the entire system. It is designed to be completely stateless and single-purpose. Its function is to evaluate a single piece of code against a single criterion and write its findings to a uniquely named file. It is invoked repeatedly by the orchestrator, once for each criterion. Its stateless design is the key to fulfilling the user's requirement for a "fresh slate" for each evaluation, preventing any possibility of context spillover between criteria checks.5File: .claude/agents/criterion-analyzer.mdname: criterion-analyzer
description: MUST BE USED to analyze a codebase against a single rubric criterion and generate a feedback file.
tools: [read, grep, find, write]You are an expert, impartial code grader and teaching assistant. You will be given three inputs:A path to the student's code directory.A single, specific criterion to evaluate.An output file number (e.g., 1, 2, 3).Your task is to perform a rigorous and isolated analysis based ONLY on the provided criterion.Thoroughly explore the student's code using find and grep to locate all relevant code snippets related to the criterion.Formulate a clear, step-by-step reasoning process for your evaluation. Explain your thought process, citing specific evidence from the code.Provide a definitive assessment (e.g., "Criterion Met," "Criterion Partially Met," "Criterion Not Met").Write your complete analysis—including the criterion itself, relevant code snippets, your step-by-step reasoning, and your final assessment—to a new file named feedback/{output_file_number}.md.Your analysis must be entirely self-contained. Do NOT make any assumptions or reference any information from other criteria. Your focus is exclusively on the single criterion provided for this specific task.3.5 The Orchestration Engine: The Master PromptThis master prompt is the script that the main Claude Code agent will execute. It defines the entire workflow, sequencing the calls to the specialized sub-agents and managing the flow of data between them.Master Prompt for Claude Code Terminal:Execute the following multi-step assignment verification workflow:Step 1: Setup Workspace.Use the workspace-manager agent to prepare the submission from this URL: ``. Wait for it to complete and confirm the path to the workspace.Step 2: Interpret Rubric.Next, use the rubric-interpreter agent on the ./prompts/ directory to extract the numbered list of evaluation criteria. Store this list for the next step.Step 3: Execute Evaluation Loop.You will now iterate through the list of criteria from Step 2. For each criterion in the list, you must perform the following sequence of actions:a. Create a directory named feedback in the project root if it does not already exist.b. Spawn a new criterion-analyzer agent. This is a new, independent invocation.c. Provide the agent with the path to the student's code (./submission_workspace/), the full text of the current criterion from the list, and the current loop number (e.g., for the first criterion, the number is 1; for the second, it is 2, and so on).d. Wait for the agent to complete its task of writing the feedback file.e. Crucially, ensure no memory or context from the criterion-analyzer's execution is carried over to the next iteration of this loop. Each analysis must start from a completely fresh slate.Step 4: Consolidate Final Report.After the loop has finished and a feedback file has been generated for every criterion, consolidate all files from the feedback/ directory into a single report named final_feedback.md. The final report should be well-structured, with clear headings for each criterion's feedback.Part 4: Advanced Implementation and Operational Best PracticesTransitioning the architectural blueprint into a production-ready, robust system requires attention to detail in prompt design, security, error handling, and observability. These advanced practices ensure the workflow is not only functional but also reliable, secure, and maintainable.4.1 Crafting High-Fidelity, Resilient PromptsThe quality of an agent's output is directly tied to the quality of its system prompt. Effective prompts are not just instructions; they are comprehensive charters that define an agent's behavior.The Power of Role-Playing: Instructing an agent with a specific persona, such as "You are an expert, impartial code grader" 3, is a powerful technique. It grounds the model's behavior, encouraging it to adopt the knowledge, tone, and reasoning patterns associated with that role, leading to more consistent and higher-quality outputs.Explicit Constraints: Defining what an agent should not do is as important as defining what it should do. For the CriterionAnalyzer, the instruction "Do NOT make any assumptions or reference any information from other criteria" is a critical constraint that enforces the required isolation. These negative constraints help prevent the model from taking creative but undesirable shortcuts.Teaching the Orchestrator to Delegate: The master prompt is the most critical piece of code in the system. As Anthropic's own research highlights, the orchestrator must be given explicit, step-by-step instructions on how to manage the sub-agents and the flow of information between them.2 The multi-step format used in section 3.5 provides this clarity, leaving little room for ambiguity and ensuring the workflow executes as designed.4.2 Mastering Tool and Permission ScopingA key advantage of the sub-agent architecture is the ability to enforce granular security controls through tool permissions.Principle of Least Privilege: This security concept dictates that any component of a system should only be granted the permissions essential to perform its intended function.5 This principle is applied throughout the proposed architecture:The WorkspaceManager is granted bash access, but its prompt limits its actions to a few specific file operations.The RubricInterpreter only needs read-only access to files (read, glob).The CriterionAnalyzer is given tools for file I/O and searching (read, write, find, grep) but is explicitly denied general bash access. This is a critical security measure that prevents the agent from accidentally or maliciously executing any code that might be present in the student's submission.Scoped Bash Commands: For agents that require bash access, permissions can be further hardened by restricting them to a specific allow-list of commands. For instance, the WorkspaceManager's tool definition could be specified as Bash(curl:*, unzip:*, mv:*, mkdir:*, rm:*), ensuring it can only execute these commands and no others.3 This significantly reduces the potential attack surface of the system.4.3 State Management, Error Handling, and ResilienceFor an autonomous system to be reliable, it must be able to handle unexpected errors gracefully.Orchestrator as State Manager: The main Claude Code agent, guided by the master prompt, is responsible for managing the overall state of the workflow. The prompt can be enhanced with error-handling logic, such as: "If a criterion-analyzer agent fails for a specific criterion, log the error and the criterion number to a file named error_log.txt, then proceed to the next criterion in the loop." This ensures that a failure in one small part of the process does not halt the entire workflow.Retry Logic: For tasks that might experience transient failures, such as the file download in the WorkspaceManager, the agent's system prompt can be augmented with simple retry logic (e.g., "If the download fails, wait 5 seconds and try again up to two more times before reporting a failure.").Idempotency: The workflow should be designed to be idempotent, meaning it can be run multiple times with the same inputs and produce the same result without causing errors. For example, the WorkspaceManager prompt includes the instruction, "If it already exists, delete its contents first to ensure a clean slate," which prevents errors on subsequent runs.4.4 Observability and DebuggingUnderstanding what an agentic system is doing and why is crucial for development and troubleshooting. Claude Code provides several tools to enhance observability.Verbose Mode and Logging: Activating verbose mode in the Claude Code terminal (often with ctrl+r) provides a detailed, real-time stream of the agent's "thought process," including which tools it is calling and the results it receives.13 This is an indispensable tool for debugging the behavior of both the orchestrator and the individual sub-agents.Structured Outputs: Designing agents to return structured, machine-readable outputs (like the simple list from the RubricInterpreter) makes the workflow more robust. The orchestrator can parse these outputs reliably, and they are easier for a human developer to inspect and validate during debugging.The "To-Do Checklist": As the orchestrator processes the master prompt, Claude Code displays a real-time to-do checklist of its plan.10 This provides crucial transparency into the agent's reasoning and execution path, allowing a human supervisor to monitor progress and intervene if the agent deviates from the intended plan.Ultimately, this entire agentic system can be viewed as a form of infrastructure as code. The complete definition of the workflow—the agents' prompts, their permissions, and the orchestration logic—is captured in a set of text-based files. This means the entire autonomous system can be stored in a Git repository, versioned, peer-reviewed, and deployed repeatably and reliably. This brings powerful software engineering best practices to the world of AI development, enabling the creation of complex, enterprise-grade systems that are both auditable and maintainable.ConclusionThe Claude sub-agent architecture provides a powerful and robust framework for building sophisticated, autonomous workflows. By leveraging the orchestrator-worker pattern, isolated context windows, and file-based definitions, it is possible to construct a modular and scalable system for student assignment verification that directly meets the core requirement of memory isolation for each evaluation criterion.The proposed three-agent system—comprising a WorkspaceManager, RubricInterpreter, and CriterionAnalyzer—demonstrates a clear division of labor that enhances reliability and security. The WorkspaceManager standardizes the input environment, the RubricInterpreter structures the task, and the stateless CriterionAnalyzer performs the core evaluation in a controlled, repeatable manner. The master orchestration prompt serves as the central logic, tying these specialized components together into a coherent and automated process.Successfully implementing this system requires a shift in mindset from traditional prompt engineering to a more structured discipline of agentic systems design. Success hinges on crafting precise system prompts, applying the principle of least privilege for tool permissions, building in robust error handling, and leveraging observability tools for debugging and monitoring. By treating the entire system as infrastructure as code—version-controlled, auditable, and repeatable—developers can build not just a functional prototype, but a production-ready solution that is secure, maintainable, and scalable. This approach represents a significant step forward in the practical application of AI for complex, real-world automation challenges.